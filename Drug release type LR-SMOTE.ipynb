{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df3cba8-1c68-4651-9292-8816adef137a",
   "metadata": {},
   "source": [
    "## Prediction of drug release type with Logistic Regression with minority oversampling technique (LR-SMOTE)\n",
    "Initialization of environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e4215e-77bf-4f15-9ef8-ff68f42db08b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score,\n",
    "    recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from functools import partial\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad088e-bd2d-45ed-baca-76ced60aec99",
   "metadata": {},
   "source": [
    "## Data loading and preparation\n",
    "Definition of variables, data loading, normalization and interpolation of the drug release profile, calculation of drug release profile AUC, and definition of drug release type (burst: AUC > 0.5, delayed: AUC <= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f769dbd-be5c-4a35-88a1-d534a80f9b99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_interp_pts = 11\n",
    "n_outer_folds = 10\n",
    "n_inner_folds = 2\n",
    "n_trials = 50\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Load data\n",
    "# ----------------------------------------------------------------------------------------\n",
    "file_path_form = 'mp_dataset_processed_no_dupes.xlsx'\n",
    "file_path_time = 'mp_dataset_processed_time_release_only.xlsx'\n",
    "formulation_df = pd.read_excel(file_path_form, engine='openpyxl')\n",
    "release_df = pd.read_excel(file_path_time, engine='openpyxl')\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Encode categorical\n",
    "# ----------------------------------------------------------------------------------------\n",
    "unique_values_emulsion = formulation_df['Formulation Method'].unique()\n",
    "mapping = {v: i for i, v in enumerate(unique_values_emulsion)}\n",
    "formulation_df['Formulation Method Encoded'] = formulation_df['Formulation Method'].map(mapping)\n",
    "formulation_df.drop(columns=['Formulation Method', 'Drug SMILES'], inplace=True)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Interpolation\n",
    "# ----------------------------------------------------------------------------------------\n",
    "group = release_df.groupby('Formulation Index')['Time']\n",
    "min_time = group.transform('min')\n",
    "max_time = group.transform('max')\n",
    "release_df['Normalized Time'] = (release_df['Time'] - min_time) / (max_time - min_time)\n",
    "normalized_times = np.linspace(0, 1, num_interp_pts)\n",
    "interpolated_dfs = []\n",
    "for formulation, g in release_df.groupby('Formulation Index'):\n",
    "    g = g.sort_values('Time')\n",
    "    time_min, time_max = g['Time'].min(), g['Time'].max()\n",
    "    g['Normalized Time'] = (g['Time'] - time_min) / (time_max - time_min)\n",
    "    interp_release = np.interp(normalized_times, g['Normalized Time'], g['Release'])\n",
    "    interpolated_dfs.append(pd.DataFrame({\n",
    "        'Formulation Index': formulation,\n",
    "        'Normalized Time': normalized_times,\n",
    "        'Interpolated Release': interp_release\n",
    "    }))\n",
    "interp_df = pd.concat(interpolated_dfs, ignore_index=True)\n",
    "\n",
    "X = formulation_df.drop(columns=['Formulation Index']).to_numpy()\n",
    "#X = formulation_df.to_numpy()  # [321, 11]\n",
    "groups = interp_df.groupby('Formulation Index')['Interpolated Release']\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# AUC and drug release type definition\n",
    "# ----------------------------------------------------------------------------------------\n",
    "auc = (\n",
    "    interp_df.groupby(\"Formulation Index\")\n",
    "      .apply(lambda g: np.trapz(g[\"Interpolated Release\"], g[\"Normalized Time\"]))\n",
    "      .reset_index(name=\"AUC\")\n",
    ")\n",
    "\n",
    "\n",
    "auc['burst'] = (auc['AUC'] > 0.5).astype(int)\n",
    "y = auc['burst'].values  # shape (n_samples,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4ebcd-e0da-4170-ba64-493da13a06ad",
   "metadata": {},
   "source": [
    "## Model Definition and Training\n",
    "Nested cross-validation with optuna hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fde5955-baa2-4d54-a590-ef411231c9d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer Fold 1\n",
      "Best params: {'C': 6.9376994718731995, 'penalty': 'l2', 'max_iter': 297, 'tol': 0.00028791072842977933, 'class_weight': None}\n",
      "Fold 1 - ACC: 0.73, AUC: 0.63, Prec: 0.83, Rec: 0.79, F1: 0.81\n",
      "\n",
      "Outer Fold 2\n",
      "Best params: {'C': 3.1785064804200625, 'penalty': 'l2', 'max_iter': 665, 'tol': 1.120930273013763e-06, 'class_weight': None}\n",
      "Fold 2 - ACC: 0.62, AUC: 0.58, Prec: 0.79, Rec: 0.65, F1: 0.71\n",
      "\n",
      "Outer Fold 3\n",
      "Best params: {'C': 27.29224298971202, 'penalty': 'l2', 'max_iter': 308, 'tol': 0.0009432910085869173, 'class_weight': None}\n",
      "Fold 3 - ACC: 0.72, AUC: 0.71, Prec: 0.89, Rec: 0.7, F1: 0.78\n",
      "\n",
      "Outer Fold 4\n",
      "Best params: {'C': 0.5289721289149582, 'penalty': 'l2', 'max_iter': 797, 'tol': 4.805167840332365e-05, 'class_weight': None}\n",
      "Fold 4 - ACC: 0.66, AUC: 0.73, Prec: 0.93, Rec: 0.57, F1: 0.7\n",
      "\n",
      "Outer Fold 5\n",
      "Best params: {'C': 0.00021924110564178025, 'penalty': 'l2', 'max_iter': 530, 'tol': 7.819087183146375e-05, 'class_weight': 'balanced'}\n",
      "Fold 5 - ACC: 0.53, AUC: 0.65, Prec: 0.74, Rec: 0.58, F1: 0.65\n",
      "\n",
      "Outer Fold 6\n",
      "Best params: {'C': 0.00013607543647676994, 'penalty': 'l2', 'max_iter': 488, 'tol': 9.192948009373685e-05, 'class_weight': 'balanced'}\n",
      "Fold 6 - ACC: 0.75, AUC: 0.83, Prec: 0.90, Rec: 0.75, F1: 0.82\n",
      "\n",
      "Outer Fold 7\n",
      "Best params: {'C': 7353.5108357080135, 'penalty': 'l2', 'max_iter': 483, 'tol': 4.153841789796908e-05, 'class_weight': 'balanced'}\n",
      "Fold 7 - ACC: 0.75, AUC: 0.74, Prec: 0.83, Rec: 0.83, F1: 0.83\n",
      "\n",
      "Outer Fold 8\n",
      "Best params: {'C': 0.000414318516104576, 'penalty': 'l2', 'max_iter': 694, 'tol': 5.275888350284398e-06, 'class_weight': None}\n",
      "Fold 8 - ACC: 0.56, AUC: 0.64, Prec: 0.75, Rec: 0.62, F1: 0.68\n",
      "\n",
      "Outer Fold 9\n",
      "Best params: {'C': 368.0411597801394, 'penalty': 'l2', 'max_iter': 461, 'tol': 0.00025783048002722757, 'class_weight': 'balanced'}\n",
      "Fold 9 - ACC: 0.69, AUC: 0.73, Prec: 0.82, Rec: 0.75, F1: 0.78\n",
      "\n",
      "Outer Fold 10\n",
      "Best params: {'C': 0.004695859756974244, 'penalty': 'l2', 'max_iter': 481, 'tol': 3.312410275573398e-05, 'class_weight': None}\n",
      "Fold 10 - ACC: 0.47, AUC: 0.54, Prec: 0.71, Rec: 0.5, F1: 0.59\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------------\n",
    "# Model wrapper for LR-SMOTE classifier\n",
    "# ----------------------------------------------------------------------------------------\n",
    "class LogisticModel:\n",
    "    def __init__(self, **params):\n",
    "        self.model = LogisticRegression(**params, solver='liblinear', random_state=42)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        proba_output = self.model.predict_proba(X)\n",
    "        if proba_output.ndim == 2 and proba_output.shape[1] == 2:\n",
    "            return proba_output[:, 1]\n",
    "        \n",
    "        return proba_output.squeeze()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Storage\n",
    "# ----------------------------------------------------------------------------------------\n",
    "stored_test_targets = []\n",
    "stored_best_models = []\n",
    "stored_best_preds = []\n",
    "stored_best_proba_all = []\n",
    "stored_metrics = []\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Nested CV setup\n",
    "# ----------------------------------------------------------------------------------------\n",
    "outer_kf = StratifiedKFold(n_splits=n_outer_folds, shuffle=True, random_state=42)\n",
    "inner_kf = StratifiedKFold(n_splits=n_inner_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Optuna objective for inner CV\n",
    "# ----------------------------------------------------------------------------------------\n",
    "def objective(trial, X_train_val, y_train_val, inner_kf):\n",
    "    params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 1e-4, 1e4, log=True),\n",
    "            \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]),\n",
    "            \"max_iter\": trial.suggest_int(\"max_iter\", 200, 1000),\n",
    "            \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-3, log=True),\n",
    "            \"class_weight\": trial.suggest_categorical(\"class_weight\", [None, 'balanced']),\n",
    "        }\n",
    "\n",
    "    \n",
    "    val_accs = []\n",
    "    for inner_train_idx, inner_val_idx in inner_kf.split(X_train_val, y_train_val):\n",
    "        X_tr, X_val = X_train_val[inner_train_idx], X_train_val[inner_val_idx]\n",
    "        y_tr, y_val = y_train_val[inner_train_idx], y_train_val[inner_val_idx]\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('smote', SMOTE(random_state=42)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', LogisticRegression(**params))\n",
    "        ])\n",
    "\n",
    "        try:\n",
    "            pipeline.fit(X_tr, y_tr)\n",
    "            preds_val = pipeline.predict(X_val)\n",
    "            acc_val = accuracy_score(y_val, preds_val)\n",
    "        except ValueError:\n",
    "            acc_val = 0.0\n",
    "\n",
    "        val_accs.append(acc_val)\n",
    "        \n",
    "    return 1 - np.mean(val_accs)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Outer CV loop\n",
    "# ----------------------------------------------------------------------------------------\n",
    "for outer_fold, (train_val_idx, test_idx) in enumerate(outer_kf.split(X, y)):\n",
    "    print(f\"\\nOuter Fold {outer_fold + 1}\")\n",
    "\n",
    "    X_train_val, y_train_val = X[train_val_idx], y[train_val_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "    stored_test_targets.append(y_test)\n",
    "\n",
    "    objective_with_data = partial(objective, X_train_val=X_train_val, y_train_val=y_train_val, inner_kf=inner_kf)\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    # Run Optuna study\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    tpe_sampler = TPESampler(seed=42) \n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=tpe_sampler)\n",
    "    study.optimize(objective_with_data, n_trials=n_trials, n_jobs=-1)\n",
    "    best_params = study.best_params\n",
    "    print(\"Best params:\", best_params)\n",
    "\n",
    "\n",
    "\n",
    "    best_pipeline = Pipeline([\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('model', LogisticModel(**best_params))\n",
    "    ])\n",
    "\n",
    "    best_pipeline.fit(X_train_val, y_train_val)\n",
    "\n",
    "    preds_best = best_pipeline.predict(X_test)\n",
    "    preds_best_proba = best_pipeline.predict_proba(X_test)\n",
    "\n",
    "    # --- Compute metrics ---\n",
    "    acc_best = accuracy_score(y_test, preds_best)\n",
    "    auc_best = roc_auc_score(y_test, preds_best_proba)\n",
    "    precision_best = precision_score(y_test, preds_best, zero_division=0)\n",
    "    recall_best = recall_score(y_test, preds_best, zero_division=0)\n",
    "    f1_best = f1_score(y_test, preds_best, zero_division=0)\n",
    "\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, preds_best).ravel()\n",
    "        specificity_best = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    except ValueError:\n",
    "        specificity_best = 0.0\n",
    "\n",
    "    stored_best_models.append(best_pipeline)\n",
    "    stored_best_preds.append(preds_best)\n",
    "    stored_best_proba_all.append(preds_best_proba)\n",
    "    stored_metrics.append({\n",
    "        \"fold\": outer_fold + 1,\n",
    "        \"accuracy\": acc_best,\n",
    "        \"auc\": auc_best,\n",
    "        \"precision\": precision_best,\n",
    "        \"recall_sensitivity\": recall_best,\n",
    "        \"specificity\": specificity_best,\n",
    "        \"f1\": f1_best\n",
    "    })\n",
    "\n",
    "    print(f\"Fold {outer_fold+1} - ACC: {acc_best:.2}, AUC: {auc_best:.2}, \"\n",
    "          f\"Prec: {precision_best:.2f}, Rec: {recall_best:.2}, F1: {f1_best:.2}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e325a306-4002-4ff6-925c-276221f3c771",
   "metadata": {},
   "source": [
    "## Performance metrics\n",
    "Accuracy, AUC, precision, recall sensitivity, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10bc482e-79a1-4a5a-bb0c-3401b9fce534",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Nested CV Results:\n",
      "ACCURACY: 0.65 ± 0.10\n",
      "AUC: 0.68 ± 0.09\n",
      "PRECISION: 0.82 ± 0.07\n",
      "RECALL_SENSITIVITY: 0.67 ± 0.11\n",
      "F1: 0.74 ± 0.08\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# Save metrics\n",
    "# ----------------------\n",
    "metrics_df = pd.DataFrame(stored_metrics)\n",
    "#metrics_df.to_csv(\"RF_class_metrics.csv\", index=False)\n",
    "#print(\"\\nRF_classn_metrics.csv\")\n",
    "\n",
    "# ----------------------\n",
    "# Final summary\n",
    "# ----------------------\n",
    "print(\"\\nFinal Nested CV Results:\")\n",
    "for metric in [\"accuracy\", \"auc\", \"precision\", \"recall_sensitivity\", \"f1\"]:\n",
    "    print(f\"{metric.upper()}: {metrics_df[metric].mean():.2f} ± {metrics_df[metric].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1ac96-7f6a-4e55-a6d7-8bfa9b1baa57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:karla_env]",
   "language": "python",
   "name": "conda-env-karla_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
