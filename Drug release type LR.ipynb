{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd8e139c-7a1b-4995-8b56-a429e937d4e7",
   "metadata": {},
   "source": [
    "## Prediction of drug release type with Logistic Regression (LR)\n",
    "Initialization of environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56e4215e-77bf-4f15-9ef8-ff68f42db08b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score,\n",
    "    recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd37172-786b-4132-9ba2-005053ae3f2e",
   "metadata": {},
   "source": [
    "## Data loading and preparation\n",
    "Definition of variables, data loading, normalization and interpolation of the drug release profile, calculation of drug release profile AUC, and definition of drug release type (burst: AUC > 0.5, delayed: AUC <= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f56faa1f-6fa8-44e4-9df6-c2eb61d32cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_interp_pts = 11\n",
    "n_outer_folds = 10\n",
    "n_inner_folds = 2\n",
    "n_trials = 50\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Load data\n",
    "# ----------------------------------------------------------------------------------------\n",
    "file_path_form = 'mp_dataset_processed_no_dupes.xlsx'\n",
    "file_path_time = 'mp_dataset_processed_time_release_only.xlsx'\n",
    "formulation_df = pd.read_excel(file_path_form, engine='openpyxl')\n",
    "release_df = pd.read_excel(file_path_time, engine='openpyxl')\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Encode categorical\n",
    "# ----------------------------------------------------------------------------------------\n",
    "unique_values_emulsion = formulation_df['Formulation Method'].unique()\n",
    "mapping = {v: i for i, v in enumerate(unique_values_emulsion)}\n",
    "formulation_df['Formulation Method Encoded'] = formulation_df['Formulation Method'].map(mapping)\n",
    "formulation_df.drop(columns=['Formulation Method', 'Drug SMILES'], inplace=True)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Interpolation\n",
    "# ----------------------------------------------------------------------------------------\n",
    "group = release_df.groupby('Formulation Index')['Time']\n",
    "min_time = group.transform('min')\n",
    "max_time = group.transform('max')\n",
    "release_df['Normalized Time'] = (release_df['Time'] - min_time) / (max_time - min_time)\n",
    "normalized_times = np.linspace(0, 1, num_interp_pts)\n",
    "interpolated_dfs = []\n",
    "for formulation, g in release_df.groupby('Formulation Index'):\n",
    "    g = g.sort_values('Time')\n",
    "    time_min, time_max = g['Time'].min(), g['Time'].max()\n",
    "    g['Normalized Time'] = (g['Time'] - time_min) / (time_max - time_min)\n",
    "    interp_release = np.interp(normalized_times, g['Normalized Time'], g['Release'])\n",
    "    interpolated_dfs.append(pd.DataFrame({\n",
    "        'Formulation Index': formulation,\n",
    "        'Normalized Time': normalized_times,\n",
    "        'Interpolated Release': interp_release\n",
    "    }))\n",
    "interp_df = pd.concat(interpolated_dfs, ignore_index=True)\n",
    "\n",
    "X = formulation_df.drop(columns=['Formulation Index']).to_numpy()\n",
    "groups = interp_df.groupby('Formulation Index')['Interpolated Release']\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# AUC and drug release type definition\n",
    "# ----------------------------------------------------------------------------------------\n",
    "auc = (\n",
    "    interp_df.groupby(\"Formulation Index\")\n",
    "      .apply(lambda g: np.trapz(g[\"Interpolated Release\"], g[\"Normalized Time\"]))\n",
    "      .reset_index(name=\"AUC\")\n",
    ")\n",
    "\n",
    "# Add a new column 'AUC_class' with 1 if AUC >= 0.5, else 0\n",
    "auc['burst'] = (auc['AUC'] > 0.5).astype(int)\n",
    "y = auc['burst'].values  # shape (n_samples,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbcc051-c6af-410f-9805-ed0d41b65b88",
   "metadata": {},
   "source": [
    "## Model Definition and Training\n",
    "Nested cross-validation with optuna hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fde5955-baa2-4d54-a590-ef411231c9d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer Fold 1\n",
      "Best params: {'C': 0.09915644566638401, 'penalty': 'l1', 'max_iter': 679, 'tol': 2.9380279387035354e-06, 'class_weight': None}\n",
      "Fold 1 - ACC: 0.7, AUC: 0.59, Prec: 0.72, Rec: 0.96, F1: 0.82\n",
      "\n",
      "Outer Fold 2\n",
      "Best params: {'C': 0.03690097105933841, 'penalty': 'l1', 'max_iter': 845, 'tol': 4.088121235908209e-06, 'class_weight': None}\n",
      "Fold 2 - ACC: 0.72, AUC: 0.61, Prec: 0.72, Rec: 1.0, F1: 0.84\n",
      "\n",
      "Outer Fold 3\n",
      "Best params: {'C': 849.9808989183019, 'penalty': 'l2', 'max_iter': 216, 'tol': 0.0008123245085588687, 'class_weight': None}\n",
      "Fold 3 - ACC: 0.69, AUC: 0.7, Prec: 0.76, Rec: 0.83, F1: 0.79\n",
      "\n",
      "Outer Fold 4\n",
      "Best params: {'C': 0.025517701734063068, 'penalty': 'l2', 'max_iter': 822, 'tol': 0.00015095969344053738, 'class_weight': None}\n",
      "Fold 4 - ACC: 0.69, AUC: 0.71, Prec: 0.71, Rec: 0.96, F1: 0.81\n",
      "\n",
      "Outer Fold 5\n",
      "Best params: {'C': 0.357371697256942, 'penalty': 'l1', 'max_iter': 396, 'tol': 1.62181917231483e-06, 'class_weight': None}\n",
      "Fold 5 - ACC: 0.78, AUC: 0.76, Prec: 0.79, Rec: 0.96, F1: 0.87\n",
      "\n",
      "Outer Fold 6\n",
      "Best params: {'C': 0.034296773893818626, 'penalty': 'l2', 'max_iter': 796, 'tol': 8.006066668243113e-06, 'class_weight': None}\n",
      "Fold 6 - ACC: 0.81, AUC: 0.86, Prec: 0.80, Rec: 1.0, F1: 0.89\n",
      "\n",
      "Outer Fold 7\n",
      "Best params: {'C': 0.14048982788948658, 'penalty': 'l1', 'max_iter': 532, 'tol': 2.9149542018943256e-06, 'class_weight': None}\n",
      "Fold 7 - ACC: 0.72, AUC: 0.74, Prec: 0.74, Rec: 0.96, F1: 0.84\n",
      "\n",
      "Outer Fold 8\n",
      "Best params: {'C': 1.1047070591176607, 'penalty': 'l2', 'max_iter': 293, 'tol': 0.00046646353710060626, 'class_weight': None}\n",
      "Fold 8 - ACC: 0.78, AUC: 0.6, Prec: 0.79, Rec: 0.96, F1: 0.87\n",
      "\n",
      "Outer Fold 9\n",
      "Best params: {'C': 0.09915644566638401, 'penalty': 'l1', 'max_iter': 679, 'tol': 2.9380279387035354e-06, 'class_weight': None}\n",
      "Fold 9 - ACC: 0.75, AUC: 0.71, Prec: 0.75, Rec: 1.0, F1: 0.86\n",
      "\n",
      "Outer Fold 10\n",
      "Best params: {'C': 849.9808989183019, 'penalty': 'l2', 'max_iter': 216, 'tol': 0.0008123245085588687, 'class_weight': None}\n",
      "Fold 10 - ACC: 0.72, AUC: 0.59, Prec: 0.74, Rec: 0.96, F1: 0.84\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------------\n",
    "# Model wrapper for LR classifier\n",
    "# ----------------------------------------------------------------------------------------\n",
    "class LogisticModel:\n",
    "    def __init__(self, **params):\n",
    "        self.model = LogisticRegression(**params, solver='liblinear', random_state=42)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        proba_output = self.model.predict_proba(X)\n",
    "        if proba_output.ndim == 2 and proba_output.shape[1] == 2:\n",
    "            return proba_output[:, 1]\n",
    "        \n",
    "        return proba_output.squeeze()\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Storage\n",
    "# ----------------------------------------------------------------------------------------\n",
    "stored_best_models = []\n",
    "stored_test_targets = []\n",
    "stored_best_preds = []\n",
    "stored_best_proba_all = []\n",
    "stored_metrics = []\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Nested CV setup\n",
    "# ----------------------------------------------------------------------------------------\n",
    "outer_kf = StratifiedKFold(n_splits=n_outer_folds, shuffle=True, random_state=42)\n",
    "inner_kf = StratifiedKFold(n_splits=n_inner_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Outer CV loop\n",
    "# ----------------------------------------------------------------------------------------\n",
    "for outer_fold, (train_val_idx, test_idx) in enumerate(outer_kf.split(X, y)):\n",
    "    print(f\"\\nOuter Fold {outer_fold + 1}\")\n",
    "\n",
    "    X_train_val, y_train_val = X[train_val_idx], y[train_val_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "    stored_test_targets.append(y_test)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    # Optuna objective for inner CV\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "                    \"C\": trial.suggest_float(\"C\", 1e-4, 1e4, log=True),\n",
    "                    \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]),\n",
    "                    \"max_iter\": trial.suggest_int(\"max_iter\", 200, 1000),\n",
    "                    \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-3, log=True),\n",
    "                    \"class_weight\": trial.suggest_categorical(\"class_weight\", [None, 'balanced']),\n",
    "                }\n",
    "\n",
    "        val_accs = []\n",
    "        inner_scaler = StandardScaler() # Scaler instance for inner loop\n",
    "\n",
    "        for inner_train_idx, inner_val_idx in inner_kf.split(X_train_val, y_train_val):\n",
    "            # Split data\n",
    "            X_tr, X_val = X_train_val[inner_train_idx], X_train_val[inner_val_idx]\n",
    "            y_tr, y_val = y_train_val[inner_train_idx], y_train_val[inner_val_idx]\n",
    "\n",
    "            # Scale data for regularized Logistic Regression\n",
    "            X_tr_scaled = inner_scaler.fit_transform(X_tr)\n",
    "            X_val_scaled = inner_scaler.transform(X_val)\n",
    "\n",
    "            model = LogisticModel(**params)\n",
    "            model.fit(X_tr_scaled, y_tr)\n",
    "            preds_val = model.predict(X_val_scaled)\n",
    "            val_accs.append(accuracy_score(y_val, preds_val))\n",
    "\n",
    "        return 1 - np.mean(val_accs)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    # Run Optuna study\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    tpe_sampler = TPESampler(seed=42) \n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=tpe_sampler)\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    best_params = study.best_params\n",
    "    print(\"Best params:\", best_params)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    # Train best model on full training data\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    outer_scaler = StandardScaler()\n",
    "    X_train_val_scaled = outer_scaler.fit_transform(X_train_val)\n",
    "    X_test_scaled = outer_scaler.transform(X_test)\n",
    "    best_model = LogisticModel(**best_params)\n",
    "    best_model.fit(X_train_val_scaled, y_train_val)\n",
    "    preds_best = best_model.predict(X_test_scaled)\n",
    "    preds_best_proba = best_model.predict_proba(X_test_scaled)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    # Compute classification metrics\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    acc_best = accuracy_score(y_test, preds_best)\n",
    "    auc_best = roc_auc_score(y_test, preds_best_proba)\n",
    "    precision_best = precision_score(y_test, preds_best, zero_division=0)\n",
    "    recall_best = recall_score(y_test, preds_best, zero_division=0)\n",
    "    f1_best = f1_score(y_test, preds_best, zero_division=0)\n",
    "\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, preds_best).ravel()\n",
    "        specificity_best = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    except ValueError:\n",
    "        specificity_best = 0.0\n",
    "\n",
    "    stored_best_models.append(best_model)\n",
    "    stored_best_preds.append(preds_best)\n",
    "    stored_best_proba_all.append(preds_best_proba)\n",
    "    stored_metrics.append({\n",
    "        \"fold\": outer_fold + 1,\n",
    "        \"accuracy\": acc_best,\n",
    "        \"auc\": auc_best,\n",
    "        \"precision\": precision_best,\n",
    "        \"recall_sensitivity\": recall_best,\n",
    "        \"f1\": f1_best\n",
    "    })\n",
    "\n",
    "    print(f\"Fold {outer_fold+1} - ACC: {acc_best:.2}, AUC: {auc_best:.2}, \"\n",
    "          f\"Prec: {precision_best:.2f}, Rec: {recall_best:.2}, F1: {f1_best:.2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6916f7f8-8089-456e-b651-bc1f853ee92f",
   "metadata": {},
   "source": [
    "## Performance metrics\n",
    "Accuracy, AUC, precision, recall sensitivity, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10bc482e-79a1-4a5a-bb0c-3401b9fce534",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Nested CV Results:\n",
      "ACCURACY: 0.74 ± 0.04\n",
      "AUC: 0.69 ± 0.09\n",
      "PRECISION: 0.75 ± 0.03\n",
      "RECALL_SENSITIVITY: 0.96 ± 0.05\n",
      "F1: 0.84 ± 0.03\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# Save metrics\n",
    "# ----------------------\n",
    "metrics_df = pd.DataFrame(stored_metrics)\n",
    "#metrics_df.to_csv(\"RF_class_metrics.csv\", index=False)\n",
    "#print(\"\\nRF_classn_metrics.csv\")\n",
    "\n",
    "# ----------------------\n",
    "# Final summary\n",
    "# ----------------------\n",
    "print(\"\\nFinal Nested CV Results:\")\n",
    "for metric in [\"accuracy\", \"auc\", \"precision\", \"recall_sensitivity\", \"f1\"]:\n",
    "    print(f\"{metric.upper()}: {metrics_df[metric].mean():.2f} ± {metrics_df[metric].std():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:karla_env]",
   "language": "python",
   "name": "conda-env-karla_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
