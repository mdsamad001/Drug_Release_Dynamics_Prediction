{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e199c68a-1f59-4aa1-9725-32a507129fb0",
   "metadata": {},
   "source": [
    "# Prediction of drug release type with Random Forest with synthetic minority over sampling technique (RF-SMOTE)\n",
    "## Initialization of environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e4215e-77bf-4f15-9ef8-ff68f42db08b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a121f7b4-b1b8-4f45-9533-0d375075280e",
   "metadata": {},
   "source": [
    "## Data loading and preparation\n",
    "Definition of variables, data loading, normalization and interpolation of the drug release profile, calculation of drug release profile AUC, and definition of drug release type (burst: AUC > 0.5, delayed: AUC <= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "467b3bb4-95bd-4fc3-93de-c618cce5cb50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_interp_pts = 11\n",
    "n_outer_folds = 10\n",
    "n_inner_folds = 2\n",
    "n_trials = 50\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Load data\n",
    "# ----------------------------------------------------------------------------------------\n",
    "file_path_form = 'mp_dataset_processed_no_dupes.xlsx'\n",
    "file_path_time = 'mp_dataset_processed_time_release_only.xlsx'\n",
    "formulation_df = pd.read_excel(file_path_form, engine='openpyxl')\n",
    "release_df = pd.read_excel(file_path_time, engine='openpyxl')\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Encode categorical\n",
    "# ----------------------------------------------------------------------------------------\n",
    "unique_values_emulsion = formulation_df['Formulation Method'].unique()\n",
    "mapping = {v: i for i, v in enumerate(unique_values_emulsion)}\n",
    "formulation_df['Formulation Method Encoded'] = formulation_df['Formulation Method'].map(mapping)\n",
    "formulation_df.drop(columns=['Formulation Method', 'Drug SMILES'], inplace=True)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Interpolation\n",
    "# ----------------------------------------------------------------------------------------\n",
    "group = release_df.groupby('Formulation Index')['Time']\n",
    "min_time = group.transform('min')\n",
    "max_time = group.transform('max')\n",
    "release_df['Normalized Time'] = (release_df['Time'] - min_time) / (max_time - min_time)\n",
    "normalized_times = np.linspace(0, 1, num_interp_pts)\n",
    "interpolated_dfs = []\n",
    "for formulation, g in release_df.groupby('Formulation Index'):\n",
    "    g = g.sort_values('Time')\n",
    "    time_min, time_max = g['Time'].min(), g['Time'].max()\n",
    "    g['Normalized Time'] = (g['Time'] - time_min) / (time_max - time_min)\n",
    "    interp_release = np.interp(normalized_times, g['Normalized Time'], g['Release'])\n",
    "    interpolated_dfs.append(pd.DataFrame({\n",
    "        'Formulation Index': formulation,\n",
    "        'Normalized Time': normalized_times,\n",
    "        'Interpolated Release': interp_release\n",
    "    }))\n",
    "interp_df = pd.concat(interpolated_dfs, ignore_index=True)\n",
    "\n",
    "X = formulation_df.drop(columns=['Formulation Index']).to_numpy()\n",
    "#X = formulation_df.to_numpy()  # [321, 11]\n",
    "groups = interp_df.groupby('Formulation Index')['Interpolated Release']\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# AUC and drug release type definition\n",
    "# ----------------------------------------------------------------------------------------\n",
    "auc = (\n",
    "    interp_df.groupby(\"Formulation Index\")\n",
    "      .apply(lambda g: np.trapz(g[\"Interpolated Release\"], g[\"Normalized Time\"]))\n",
    "      .reset_index(name=\"AUC\")\n",
    ")\n",
    "\n",
    "auc['burst'] = (auc['AUC'] > 0.5).astype(int)\n",
    "y = auc['burst'].values  # shape (n_samples,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f864046b-504a-400c-b1e7-30e031d1a59b",
   "metadata": {},
   "source": [
    "## Model Definition and Training\n",
    "Nested cross-validation with optuna hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fde5955-baa2-4d54-a590-ef411231c9d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer Fold 1\n",
      "Best params: {'n_estimators': 53, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}\n",
      "Fold 1 - ACC: 0.73, AUC: 0.67, Prec: 0.80, Rec: 0.83, F1: 0.82\n",
      "\n",
      "Outer Fold 2\n",
      "Best params: {'n_estimators': 223, 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True}\n",
      "Fold 2 - ACC: 0.72, AUC: 0.81, Prec: 0.77, Rec: 0.87, F1: 0.82\n",
      "\n",
      "Outer Fold 3\n",
      "Best params: {'n_estimators': 264, 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}\n",
      "Fold 3 - ACC: 0.72, AUC: 0.74, Prec: 0.85, Rec: 0.74, F1: 0.79\n",
      "\n",
      "Outer Fold 4\n",
      "Best params: {'n_estimators': 258, 'max_depth': 15, 'min_samples_split': 17, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}\n",
      "Fold 4 - ACC: 0.78, AUC: 0.84, Prec: 0.90, Rec: 0.78, F1: 0.84\n",
      "\n",
      "Outer Fold 5\n",
      "Best params: {'n_estimators': 273, 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}\n",
      "Fold 5 - ACC: 0.78, AUC: 0.81, Prec: 0.87, Rec: 0.83, F1: 0.85\n",
      "\n",
      "Outer Fold 6\n",
      "Best params: {'n_estimators': 252, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}\n",
      "Fold 6 - ACC: 0.88, AUC: 0.88, Prec: 0.92, Rec: 0.92, F1: 0.92\n",
      "\n",
      "Outer Fold 7\n",
      "Best params: {'n_estimators': 127, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}\n",
      "Fold 7 - ACC: 0.81, AUC: 0.9, Prec: 0.85, Rec: 0.92, F1: 0.88\n",
      "\n",
      "Outer Fold 8\n",
      "Best params: {'n_estimators': 100, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}\n",
      "Fold 8 - ACC: 0.75, AUC: 0.65, Prec: 0.81, Rec: 0.88, F1: 0.84\n",
      "\n",
      "Outer Fold 9\n",
      "Best params: {'n_estimators': 152, 'max_depth': 13, 'min_samples_split': 14, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}\n",
      "Fold 9 - ACC: 0.81, AUC: 0.91, Prec: 0.91, Rec: 0.83, F1: 0.87\n",
      "\n",
      "Outer Fold 10\n",
      "Best params: {'n_estimators': 264, 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}\n",
      "Fold 10 - ACC: 0.66, AUC: 0.7, Prec: 0.78, Rec: 0.75, F1: 0.77\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------------\n",
    "# Model wrapper for Random Forest Classifier\n",
    "# ----------------------------------------------------------------------------------------\n",
    "class RandomForestModel:\n",
    "    def __init__(self, **params):\n",
    "        self.model = RandomForestClassifier(**params, random_state=42, n_jobs=-1)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "\n",
    "    def evaluate(self, X, y_true):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "\n",
    "    def feature_importances(self):\n",
    "        return self.model.feature_importances_\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Storage\n",
    "# ----------------------------------------------------------------------------------------\n",
    "stored_best_models = []\n",
    "stored_best_preds = []\n",
    "stored_best_proba = []\n",
    "stored_test_targets = []\n",
    "stored_metrics = []\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Nested CV setup\n",
    "# ----------------------------------------------------------------------------------------\n",
    "outer_kf = StratifiedKFold(n_splits=n_outer_folds, shuffle=True, random_state=42)\n",
    "inner_kf = StratifiedKFold(n_splits=n_inner_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Outer CV loop\n",
    "# ----------------------------------------------------------------------------------------\n",
    "for outer_fold, (train_val_idx, test_idx) in enumerate(outer_kf.split(X, y)):\n",
    "    print(f\"\\nOuter Fold {outer_fold + 1}\")\n",
    "\n",
    "    X_train_val, y_train_val = X[train_val_idx], y[train_val_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "    stored_test_targets.append(y_test)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    # Optuna objective for inner CV\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None]),\n",
    "            \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False])\n",
    "        }\n",
    "\n",
    "        val_accs = []\n",
    "\n",
    "        for inner_train_idx, inner_val_idx in inner_kf.split(X_train_val, y_train_val):\n",
    "            X_tr, X_val = X_train_val[inner_train_idx], X_train_val[inner_val_idx]\n",
    "            y_tr, y_val = y_train_val[inner_train_idx], y_train_val[inner_val_idx]\n",
    "\n",
    "            # Apply SMOTE to training fold\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_tr_res, y_tr_res = smote.fit_resample(X_tr, y_tr)\n",
    "\n",
    "            model = RandomForestModel(**params)\n",
    "            model.fit(X_tr_res, y_tr_res)\n",
    "            val_accs.append(model.evaluate(X_val, y_val))\n",
    "\n",
    "        return 1 - np.mean(val_accs)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    # Run Optuna study\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    tpe_sampler = TPESampler(seed=42) \n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=tpe_sampler)\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    best_params = study.best_params\n",
    "    print(\"Best params:\", best_params)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    # Train best model on full training data with SMOTE\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_val_res, y_train_val_res = smote.fit_resample(X_train_val, y_train_val)\n",
    "\n",
    "    best_model = RandomForestModel(**best_params)\n",
    "    best_model.fit(X_train_val_res, y_train_val_res)\n",
    "    preds_best = best_model.predict(X_test)\n",
    "    preds_proba_best = best_model.predict_proba(X_test)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    # Compute metrics\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    acc_best = accuracy_score(y_test, preds_best)\n",
    "    precision_best = precision_score(y_test, preds_best, zero_division=0)\n",
    "    recall_best = recall_score(y_test, preds_best, zero_division=0)\n",
    "    f1_best = f1_score(y_test, preds_best, zero_division=0)\n",
    "    auc_best = roc_auc_score(y_test, preds_proba_best)\n",
    "\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, preds_best).ravel()\n",
    "        specificity_best = tn / (tn + fp)\n",
    "    except ValueError:\n",
    "        specificity_best = 0.0\n",
    "\n",
    "    stored_best_models.append(best_model)\n",
    "    stored_best_preds.append(preds_best)\n",
    "    stored_best_proba.append(preds_proba_best)\n",
    "    stored_metrics.append({\n",
    "        \"fold\": outer_fold + 1,\n",
    "        \"accuracy\": acc_best,\n",
    "        \"precision\": precision_best,\n",
    "        \"recall_sensitivity\": recall_best,\n",
    "        \"specificity\": specificity_best,\n",
    "        \"f1\": f1_best,\n",
    "        \"auc\": auc_best\n",
    "    })\n",
    "\n",
    "    print(f\"Fold {outer_fold+1} - ACC: {acc_best:.2}, AUC: {auc_best:.2}, \"\n",
    "          f\"Prec: {precision_best:.2f}, Rec: {recall_best:.2}, F1: {f1_best:.2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943de65f-9a87-40d0-afa5-dbbbd9e0e850",
   "metadata": {},
   "source": [
    "## Performance metrics\n",
    "Accuracy, AUC, precision, recall sensitivity, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2c1ac96-7f6a-4e55-a6d7-8bfa9b1baa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Nested CV Results:\n",
      "ACCURACY: 0.76 ± 0.06\n",
      "AUC: 0.79 ± 0.09\n",
      "PRECISION: 0.85 ± 0.05\n",
      "RECALL_SENSITIVITY: 0.83 ± 0.06\n",
      "F1: 0.84 ± 0.04\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# Save metrics\n",
    "# ----------------------\n",
    "metrics_df = pd.DataFrame(stored_metrics)\n",
    "#metrics_df.to_csv(\"RF_class_metrics.csv\", index=False)\n",
    "#print(\"\\nRF_classn_metrics.csv\")\n",
    "\n",
    "# ----------------------\n",
    "# Final summary\n",
    "# ----------------------\n",
    "print(\"\\nFinal Nested CV Results:\")\n",
    "for metric in [\"accuracy\", \"auc\", \"precision\", \"recall_sensitivity\", \"f1\"]:\n",
    "    print(f\"{metric.upper()}: {metrics_df[metric].mean():.2f} ± {metrics_df[metric].std():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:karla_env]",
   "language": "python",
   "name": "conda-env-karla_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
